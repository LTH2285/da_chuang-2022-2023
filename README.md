# 简介
2022-2023大创，进行事件论元抽取，构建数据库

该代码实现了一个基于PyTorch的BiLSTM_CRF模型用于英文命名实体识别。本模型使用了预训练的BERT模型作为输入，以双向LSTM层提取序列特征，全连接层将LSTM层的输出映射到命名实体标签的概率，并使用CRF层对标签进行归一化，输出最终的预测标签序列。


在代码的实现过程中，需要指定BERT模型的路径和将每个命名实体标签分配到一个int型的整数。BiLSTM_CRF对象可以使用其提供的训练、预测和评估命名实体识别任务的方法进行实例化和使用。


# 详细解释


## 模型结构

BertModel 对输入文本序列进行编码，转换为向量表示。这些向量被输入到双向LSTM层中，提取序列特征。全连接层将LSTM层的输出映射到命名实体标签的概率。CRF层对标签进行归一化，输出最终的预测标签序列。


## 特殊函数

_forward_alg()：实现了前向算法，用于计算所有可能的标注序列的分数总和。

_score_sentence()：实现了动态规划算法，用于得出给定标注序列的分数。

_viterbi_decode()：实现了Viterbi算法，用于找到给定输入最有可能的标注序列。


## 初始化函数

在初始化函数中定义了一些变量和对象：tag_to_ix表示每个标签和对应标签 id 的字典；hidden_dim表示 LSTM 的隐藏状态的维度；bert_tokenizer和bert表示存放BERT模型和BERT分词器的对象；lstm表示存放LSTM模型的对象；hidden2tag表示全连接层模型，将输入序列的输出映射到标签空间的概率；transitions表示CRF层模型，转移矩阵的元素为模型预测从一个标签转移到另一个标签的概率，并初始化为符合预设标准的随机值；START_TAG和STOP_TAG分别表示起始和终止的标签；optimizer表示Adam优化器。


## 功能函数

init_hidden()：用于初始化LSTM的隐藏状态。


_log_sum_exp()：用于计算批次中每个标记的分数总和。


_neg_log_likelihood()：评估该句子及其对应的真实标签的负对数似然。


_forward_alg()：用于得出给定输入序列的所有可能的标注序列的分数总和。


_score_sentence()：计算给定标注序列的分数。


_viterbi_decode()：用于找到给定输入最有可能的标注序列。


embed_and_tag()：将输入文本序列转换为向量表示，并进行标注。


train()：使用样本数据训练模型。


evaluate()：使用测试数据评估模型的性能。


forward()：对输入文本序列进行标注。


## 总结

该代码实现了一个基于PyTorch的BiLSTM_CRF模型用于英文命名实体识别。本代码采用BERT模型预训练的方式，能够高效地提取文本特征。然后，通过BiLSTM层建立了文本特征的上下文关系，然后使用CRF层对命名实体识别任务中的标签进行归一化，提高了模型的命名实体识别精度。此外，模型的代码结构清晰、模块化，也方便了模型的训练、调参和使用。
